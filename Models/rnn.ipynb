{"cells":[{"cell_type":"markdown","metadata":{"id":"8fTe8WJD7CNi"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20299,"status":"ok","timestamp":1657979143188,"user":{"displayName":"Piotr KulpiÅ„ski","userId":"05873078239734830768"},"user_tz":-120},"id":"GuA7OFVyGcuL","outputId":"d1fa2263-413b-4702-df32-f8427f4b2e50"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/1NSBJKoA0FA5BeDWR8bNo5tPgA5lCU8yv/CIL 2022\n","'Bert inspiration'\n"," BoW_v2.ipynb\n"," code\n"," data\n"," Models\n"," Notes.gdoc\n"," On_Processed_Bag-of-words_baseline.ipynb\n"," papers_to_possible_reference\n"," Preprocessing\n"," Project_2_Bag-of-words_baseline.ipynb\n"," __pycache__\n"," resources\n"," Results.gsheet\n"," template.ipynb\n","'trained Glove_LogisticRegression(C=1, max_iter=1000).pkl'\n"," trash\n"," tut1-model.pt\n","'Word embeddings'\n"," XGBoost\n"]}],"source":["#Gabriel/Piotrek: Choose index from 1 - 8 for variable PREPROCESSING_OPTIONS[INDEX HERE]\n","#Run the notebook from top to bottom, for model regression (and urban dictionary basic)\n","#Save stats; rename it to UD+old_name, and move it to appopriate folder\n","#LIFEHACK: Make multiple (>2) duplicates of this notebook, open the duplicates in another tab/window, use different indeces, and run them in parallel.\n","\n","#In this cell, there are various option for the user to freely choose:\n","#embedding_choice\n","#PREPROCESSING_CHOICE\n","\n","import time\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import pandas as pd\n","import numpy as np\n","import torch\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from nltk.tokenize import TweetTokenizer\n","tknzr = TweetTokenizer()\n","\n","from gensim.models import Word2Vec\n","from gensim.models import FastText\n","from gensim.models import KeyedVectors\n","#from gensim.test.utils import common_texts\n","import gensim.downloader as api\n","import gensim\n","\n","#helper function to save models and stats\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n","import pickle\n","\n","\n","use_drive = True\n","if use_drive:\n","  PATH = \"/content/drive/MyDrive/CIL 2022/\"\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  %cd /content/drive/MyDrive/CIL 2022/\n","  !ls\n","else:\n","  PATH = \"./\"\n","\n","#save model\n","# now you can save it to a file\n","# with open('filename.pkl', 'wb') as f:\n","#     pickle.dump(clf, f)\n","\n","# # and later you can load it\n","# with open('filename.pkl', 'rb') as f:\n","#     clf = pickle.load(f)\n","\n","#1 = stanford glove\n","#2 = word2vec\n","#3 = fasttext\n","#4 = basic urban dictionary embedding\n","#5 = phrase urban dictionary embedding\n","def get_embedding_name(embedding_id):\n","  if embedding_id == 1:\n","    return \"stanford glove\"\n","  elif embedding_id == 2:\n","    return \"word2vec\"\n","  elif embedding_id == 3:\n","    return \"fasttext\"\n","  elif embedding_id == 4:\n","    return \"basic urban dictionary\"\n","  elif embedding_id == 5:\n","    return \"phrase urban dictionary\"\n","  else:\n","    return \"User error: embedding id does not exist.\"\n","\n","#Saving trained model\n","def save_model(model, model_name):\n","  name_of_file_model = \"trained \" + model_name + \".pkl\"\n","  with open(name_of_file_model, 'wb') as f:\n","    pickle.dump(model, f)\n","  print(\"Model saved.\")\n","\n","#Saving stats of model to a file\n","def save_stats_to_file(y_val, y_val_pred, model_name):\n","  name_of_file_stats = get_embedding_name(embedding_choice) + \"+\" + model_name + PREPROCESSING_CHOICE + \".txt\"\n","  # name_of_file_model = \"trained \" + model_name + \".pkl\"\n","  # print(\"Saving model to file.\")\n","  # with open(name_of_file_model, 'wb') as f:\n","  #   pickle.dump(model, f)\n","  print(\"Saving model relevant stats to file.\")\n","  file_obj = open(name_of_file_stats, \"w\", encoding=\"utf8\")\n","  file_obj.write(f'use_drive: {use_drive}\\n')\n","  # file_obj.write(f'LOAD_FROM_SPLITTED_DATASET: {LOAD_FROM_SPLITTED_DATASET}\\n')\n","  # file_obj.write(f'WRITE_SPLITTED_DATASET: {WRITE_SPLITTED_DATASET}\\n')\n","  # file_obj.write(f'REMOVE_DUPLICATES_FROM_TRAINING: {REMOVE_DUPLICATES_FROM_TRAINING}\\n')\n","  file_obj.write(f'PREPROCESSING_CHOICE: {PREPROCESSING_CHOICE}\\n')\n","  file_obj.write(f'embedding_choice: {embedding_choice}\\n')\n","  file_obj.write(f'embedding_name: {get_embedding_name(embedding_choice)}\\n')\n","  file_obj.write(f'dimension_of_embedding: {dimension_of_embedding}\\n')\n","  file_obj.write(f'Model name: {model_name}\\n')\n","  file_obj.write(f'Acc: {accuracy_score(y_val, y_val_pred)}\\n')\n","  file_obj.write(f'Recall: {recall_score(y_val, y_val_pred)}\\n')\n","  file_obj.write(f'Precision: {precision_score(y_val, y_val_pred)}\\n')\n","  file_obj.write(f'F1: {f1_score(y_val, y_val_pred)}\\n')\n","  file_obj.write(f'ROC_AUC: {roc_auc_score(y_val, y_val_pred)}\\n')\n","  file_obj.close()\n","  print(f'Acc: {accuracy_score(y_val, y_val_pred)}')\n","  print(f'Recall: {recall_score(y_val, y_val_pred)}')\n","  print(f'Precision: {precision_score(y_val, y_val_pred)}')\n","  print(f'F1: {f1_score(y_val, y_val_pred)}')\n","  print(f'ROC_AUC: {roc_auc_score(y_val, y_val_pred)}')"]},{"cell_type":"markdown","metadata":{"id":"CsAT4LLO7tud"},"source":["# Choices"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XDU3yME88BbW"},"outputs":[],"source":["#Choose embedding below\n","#1 = stanford glove\n","#2 = word2vec\n","#3 = fasttext\n","#4 = basic urban dictionary embedding\n","#5 = phrase urban dictionary embedding\n","embedding_choice = 1\n","\n","USE_DICTIONARY = True\n","embedding_non_dict_model = None\n","embedding_dict = dict()\n","#SET FLAG \"USE_DICTIONARY\" to determine if we work with a dictionary or a loaded pretrained model\n","if (embedding_choice == 2) or (embedding_choice == 3):\n","  USE_DICTIONARY = False\n","\n","# HYPERPARAMETERS\n","# LOAD_FROM_SPLITTED_DATASET = True\n","# WRITE_SPLITTED_DATASET = True\n","# REMOVE_DUPLICATES_FROM_TRAINING = False\n","\n","#option 0 - 8\n","PREPROCESSING_OPTIONS = [ \"raw\",\n","\"no-stemming_no-lemmatize_no-stopwords_no-spellcorrect\",\n","\"no-stemming_no-lemmatize_with-stopwords_no-spellcorrect\",\n","\"no-stemming_no-lemmatize_with-stopwords_with-spellcorrect\",\n","\"no-stemming_with-lemmatize_with-stopwords_no-spellcorrect\",\n","\"no-stemming_with-lemmatize_with-stopwords_with-spellcorrect\",\n","\"with-stemming_no-lemmatize_with-stopwords_no-spellcorrect\",\n","\"with-stemming_with-lemmatize_no-stopwords_with-spellcorrect\",\n","\"with-stemming_with-lemmatize_with-stopwords_no-spellcorrect\" ]\n","PREPROCESSING_CHOICE = PREPROCESSING_OPTIONS[8] # one from PREPROCESSING_OPTIONS\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gK44dOWs-o-T"},"source":["#Choose embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G6BN0Yc_pJR4"},"outputs":[],"source":["#From the glove embedding file\n","\n","#https://github.com/RaRe-Technologies/gensim-data#datasets\n","#https://kavita-ganesan.com/easily-access-pre-trained-word-embeddings-with-gensim/#.YsGEXexBxE4\n","\n","#depending on choice, we choose a different file\n","if embedding_choice == 1:\n","  #stanford\n","  #files offers dimension_of_embedding = {25,50,100,200}\n","  dimension_of_embedding = 200 #can also modify this\n","\n","  #easy:\n","  # model_name = \"glove-twitter-\" + str(dimension_of_embedding)\n","  # model = api.load(model_name)\n","\n","  #directly from stanford glove file:\n","  path_to_embedding_file = \"/content/drive/MyDrive/CIL 2022/Word embeddings\"\n","  path_to_embedding_file += \"/Glove/glove.twitter.27B.\" + str(dimension_of_embedding) + \"d.txt\"\n","\n","  # FLAG_shaped_already_saved = False\n","  # shape_of_np_vector = None\n","\n","  embedding_file_obj = open(path_to_embedding_file, \"r\", encoding = \"utf8\")\n","  for line in embedding_file_obj:\n","    #Check if line consists only of ASCII characters (no Chinese/Japanse/Arabic, etc. expressions)\n","    #There were some lines that had non-ASCII characters.\n","    if line.isascii():\n","      word_n_vector = line.split()\n","      embedding_dict[word_n_vector[0]] = np.array(word_n_vector[1:], dtype=np.float64)\n","      # if not FLAG_shaped_already_saved:\n","      #   shape_of_np_vector = np.array(word_n_vector[1:], dtype=np.float64).shape\n","      #   FLAG_shaped_already_saved = True\n","\n","  embedding_file_obj.close\n","\n","  #add <UNKNOWN> token to vocabulary\n","  #choose the 0 vector as the corresponding embedding\n","  embedding_dict[\"<UNKNOWN>\"] = np.zeros(dimension_of_embedding, dtype=np.float64)\n","  embedding_dict[\"<PAD>\"] = np.zeros(dimension_of_embedding, dtype=np.float64)\n","  #embedding_dict[\"<UNKNOWN>\"] = np.zeros(shape_of_np_vector, dtype=np.float64)\n","\n","\n","elif embedding_choice == 2:\n","  \n","#https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html\n","\n","  #easier:\n","  dimension_of_embedding = 300\n","  #choose which embeddings\n","  # model_name = \"word2vec-google-news-300\"\n","  # model_name = \"word2vec-ruscorpora-300\" #get Russian vocabulary\n","  \n","  #IF PRE-TRAINED MODEL NOT STORED, LOAD IT FROM WEB\n","  model_name = \"word2vec-google-news-\" + str(dimension_of_embedding)\n","  embedding_non_dict_model = api.load(model_name) #load pretrained model\n","  #embedding_non_dict_model.save_word2vec_format('w2v_pre_trained_model.txt', binary=False) #store it #indicate path\n","\n","  #ELSE LOAD IT FROM FILE\n","  # pre_trained_model = \"/content/drive/MyDrive/CIL 2022/Models/w2v_pre_trained_model.txt\"\n","  # model = KeyedVectors.load_word2vec_format(pre_trained_model, binary=False)\n","\n","elif embedding_choice == 3:\n","\n","#https://radimrehurek.com/gensim/auto_examples/tutorials/run_fasttext.html#sphx-glr-auto-examples-tutorials-run-fasttext-py\n","  \n","  dimension_of_embedding = 300\n","  #choose which embeddings\n","  # model_name = \"word2vec-google-news-300\"\n","  # model_name = \"word2vec-ruscorpora-300\" #get Russian vocabulary\n","\n","  #IF PRE-TRAINED MODEL NOT STORED, LOAD IT FROM WEB\n","  model_name = \"fasttext-wiki-news-subwords-\" + str(dimension_of_embedding)\n","  embedding_non_dict_model = api.load(model_name) #load pretrained model\n","  \n","\n","  #ELSE LOAD IT FROM FILE\n","  # pre_trained_model = \"/content/drive/MyDrive/CIL 2022/Models/fasttext_pre_trained_model.txt\"\n","  # model = KeyedVectors.load_fasttext_format(pre_trained_model, binary=False)\n","  \n","\n","elif (embedding_choice == 4) or (embedding_choice == 5):\n","  \n","  #see https://aclanthology.org/2020.lrec-1.586.pdf for difference.\n","\n","  #TODO: figure out what the binaries do\n","  path_to_embedding_file = None\n","  if embedding_choice == 4:\n","    path_to_embedding_file = \"/content/drive/MyDrive/CIL 2022/Word embeddings/urbanDictionary/ud_basic.vec\"\n","  else:\n","    path_to_embedding_file = \"/content/drive/MyDrive/CIL 2022/Word embeddings/urbanDictionary/ud_phrase.vec\"\n","  \n","\n","  embedding_file_obj = open(path_to_embedding_file, \"r\")\n","  vocab_size_and_embedding_dim = embedding_file_obj.readline().split()\n","\n","  vocab_size = int(vocab_size_and_embedding_dim[0])\n","  dimension_of_embedding = int(vocab_size_and_embedding_dim[1])\n","\n","  # FLAG_shaped_already_saved = False\n","  # shape_of_np_vector = None\n","\n","  for line in embedding_file_obj:\n","    word_n_vector = line.split()\n","    embedding_dict[word_n_vector[0]] = np.array(word_n_vector[1:], dtype=np.float64)\n","    # if not FLAG_shaped_already_saved:\n","    #   shape_of_np_vector = np.array(word_n_vector[1:], dtype=np.float64).shape\n","    #   FLAG_shaped_already_saved = True\n","\n","  embedding_file_obj.close\n","\n","  #add <UNKNOWN> token to vocabulary\n","  #choose the 0 vector as the corresponding embedding\n","  embedding_dict[\"<UNKNOWN>\"] = np.zeros(dimension_of_embedding, dtype=np.float64)\n","  embedding_dict[\"<PAD>\"] = np.zeros(dimension_of_embedding, dtype=np.float64)\n","  #embedding_dict[\"<UNKNOWN>\"] = np.zeros(shape_of_np_vector, dtype=np.float64)\n","else:\n","  print(\"Error: embedding not recognized\")\n","\n","#init method"]},{"cell_type":"markdown","metadata":{"id":"VsdyEoMRqR7W"},"source":["# Tokenize to embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AIZrOTIOqRhG"},"outputs":[],"source":["\n","#https://www.nltk.org/api/nltk.tokenize.html\n","\n","#feature = average of vectors of tokens occuring in tweet\n","def transform_to_embeddings(list_of_sentences, embedding_model, embedding_model_type, word_to_ix):\n","\n","  max_size = 100\n","  sentences = torch.zeros(len(list_of_sentences), max_size, dtype=torch.long, device='cuda')#to return\n","\n","    #for each tweet:\n","    #for each token:\n","    #get embedding vector\n","    #compute average\n","    #store it in a list with corresponding label\n","  pad_index = word_to_ix.get('<PAD>')\n","\n","  for line, tweet in enumerate(list_of_sentences):\n","    tokenized_tweet = tknzr.tokenize(tweet)\n","    indexed_embeddings = torch.tensor([pad_index]*max_size, dtype=torch.long, device='cuda')\n","    \n","    for index, word in enumerate(tokenized_tweet):\n","  \n","      word_index = word_to_ix.get(word)\n","      if word_index == None:\n","        word_index = word_to_ix.get(\"<UNKNOWN>\")\n","\n","      indexed_embeddings[index] = word_index\n","    sentences[line] = indexed_embeddings\n","\n","  return sentences\n"]},{"cell_type":"markdown","metadata":{"id":"VXMlp9APzTew"},"source":["#Create training and test set"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4692,"status":"ok","timestamp":1657979335687,"user":{"displayName":"Piotr KulpiÅ„ski","userId":"05873078239734830768"},"user_tz":-120},"id":"vrxzzY3yGlZG","outputId":"d1886f0c-c749-4189-d8eb-dda625f21a1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["1967351\n"]}],"source":["def read_file_and_strip(filename):\n","  lines = []\n","  with open(filename) as file:\n","    for line in file:\n","      lines.append(line.strip())\n","  return np.array(lines)\n","\n","def read_data():\n","  dataset_path = PATH + \"data/\" + PREPROCESSING_CHOICE + \"/\"\n","\n","  train_sentences = read_file_and_strip(dataset_path + \"train_sentences.txt\")\n","  train_labels = read_file_and_strip(dataset_path + \"train_labels.txt\").astype(int)\n","  val_sentences = read_file_and_strip(dataset_path + \"val_sentences.txt\")\n","  val_labels = read_file_and_strip(dataset_path + \"val_labels.txt\").astype(int)\n","  \n","  return train_sentences, train_labels, val_sentences, val_labels\n","\n","train_sentences, train_labels, val_sentences, val_labels = read_data()\n","print(len(train_sentences))\n","\n","\n","embedding_model = None\n","if USE_DICTIONARY:\n","  embedding_model_type = \"DICT\"\n","  embedding_model = embedding_dict\n","else:\n","  embedding_model_type = \"NON-DICT\"\n","  embedding_model = embedding_non_dict_model\n"]},{"cell_type":"markdown","metadata":{"id":"4v1Bawbd9bu4"},"source":["## Transform the sentences into tensor vectors of word indexes from the vocab corpus"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zDbne3KmGtgh"},"outputs":[],"source":["# Create a vocabulary corpus\n","word_to_ix = {word: i for i, word in enumerate(embedding_model)}\n","\n","train_data = transform_to_embeddings(train_sentences, embedding_model, embedding_model_type, word_to_ix)\n","\n","val_data = transform_to_embeddings(val_sentences, embedding_model, embedding_model_type, word_to_ix)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O1hySBw1BD9M"},"outputs":[],"source":["\n","train_labels = torch.tensor(train_labels, dtype=torch.long, device='cuda') \n","\n","val_labels = torch.tensor(val_labels, dtype=torch.long, device='cuda') "]},{"cell_type":"markdown","source":["## Transform the embeddings into float tensor"],"metadata":{"id":"UKQ5p9_FbjDJ"}},{"cell_type":"code","source":["# Transform the embeddings into float tensor with just weights and indexes of \n","# those weights representing the words\n","test = np.zeros((len(embedding_model), dimension_of_embedding))\n","for i, word in enumerate(embedding_model):\n","  test[i] = embedding_model[word]\n","\n","pretrained_embeddings = torch.tensor(test, dtype=torch.float, device='cuda')"],"metadata":{"id":"R7CRtE5UbobA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5isaz7VhZyM8"},"source":["#Model = RNN"]},{"cell_type":"markdown","metadata":{"id":"iLFoOdq392d0"},"source":["## Put tensor into a dataset for batching"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2gLKemU_IoJu"},"outputs":[],"source":["class Dataset(torch.utils.data.Dataset):\n","  'Characterizes a dataset for PyTorch'\n","  def __init__(self, list_id, labels):\n","        'Initialization'\n","        self.labels = labels\n","        self.list_id = list_id\n","\n","  def __len__(self):\n","        'Denotes the total number of samples'\n","        return len(self.list_id)\n","\n","  def __getitem__(self, index):\n","        'Generates one sample of data'\n","\n","\n","        # Load data and get label\n","        X = self.list_id[index]\n","        y = torch.tensor([self.labels[index]], dtype=torch.long, device='cuda')\n","        return X, y "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qObEZIzLx1o6"},"outputs":[],"source":["BATCH_SIZE = 64\n","\n","dataset = Dataset(train_data, train_labels)\n","my_dataloader = DataLoader(dataset, batch_size=64) # create your dataloader\n","\n","val_dataset = Dataset(val_data, val_labels)\n","val_dataloader = DataLoader(val_dataset, batch_size=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1657979948684,"user":{"displayName":"Piotr KulpiÅ„ski","userId":"05873078239734830768"},"user_tz":-120},"id":"by5xXiE9nwgd","outputId":"05d87c34-9898-4d0d-c22f-85e0c7b2c56a"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0, device='cuda:0')\n"]}],"source":["test = torch.tensor([0, 0, 0], dtype=torch.long).to('cuda')\n","print(test[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1657979948684,"user":{"displayName":"Piotr KulpiÅ„ski","userId":"05873078239734830768"},"user_tz":-120},"id":"8c7QaPhcGRyz","outputId":"6eb5e659-2d7b-4676-a048-93d1c23428d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["print(train_data.device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1657979948685,"user":{"displayName":"Piotr KulpiÅ„ski","userId":"05873078239734830768"},"user_tz":-120},"id":"0-uL5w7yKV0F","outputId":"2554a97d-bae2-4f19-aaed-2e9cddeb0c92"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'list'>\n","<class 'torch.Tensor'>\n"]}],"source":["\n","for index,batch in enumerate(my_dataloader):\n","  if(index == 1):\n","    text, l = batch\n","    print(type(batch))\n","    print(type(l))\n","    break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xG_3f5udvSzT"},"outputs":[],"source":["#del train_data\n","#del train_labels"]},{"cell_type":"markdown","metadata":{"id":"atmM6qMuHYyX"},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l4hl3zzfoZiz"},"outputs":[],"source":["\n","class RNN(nn.Module):\n","    def __init__(self, input, embedding_dim, hidden_dim, output_dim, pad_id):\n","        \n","        super().__init__()\n","        \n","        self.embedding = nn.Embedding(input, embedding_dim, padding_idx=pad_id)\n","        \n","        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n","        \n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","        \n","    def forward(self, text):\n","\n","        #text = [sent len, batch size]\n","        \n","        embedded = self.embedding(text)\n","        \n","        #embedded = [sent len, batch size, emb dim]\n","        \n","        output, hidden = self.rnn(embedded)\n","        \n","        #output = [sent len, batch size, hid dim]\n","        #hidden = [1, batch size, hid dim]\n","        \n","        assert torch.equal(output[-1,:], hidden.squeeze(0))\n","        \n","        return self.fc(hidden.squeeze(0))"]},{"cell_type":"markdown","metadata":{"id":"VTdMqibYHbVC"},"source":["## Training method"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J9W6WD0pxdBg"},"outputs":[],"source":["\n","def train(model, iterator, optimizer, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.train()\n","    \n","    for index, batch in enumerate(iterator):\n","        \n","        text, labels = batch\n","\n","       # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n","        # into integer indices and wrap them in tensors)\n","        \n","        \n","        optimizer.zero_grad()\n","\n","        predictions = model(text.T)\n","        \n","        loss = criterion(predictions, labels.type(torch.FloatTensor).to('cuda'))\n","        \n","        acc = binary_accuracy(predictions, labels.type(torch.FloatTensor).to('cuda'))\n","        \n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","          \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"]},{"cell_type":"markdown","metadata":{"id":"8nvUGXRsHedy"},"source":["## Evaluation method"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l7P0q5dHxewi"},"outputs":[],"source":["def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for index, batch in enumerate(iterator):\n","          text, labels = batch\n","\n","          predictions = model(text.T)\n","          \n","          loss = criterion(predictions, labels.type(torch.FloatTensor).to('cuda'))\n","          \n","          acc = binary_accuracy(predictions, labels.type(torch.FloatTensor).to('cuda'))\n","          \n","\n","          epoch_loss += loss.item()\n","          epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FATKGGokxgw0"},"outputs":[],"source":["\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"]},{"cell_type":"markdown","metadata":{"id":"raGFUcxHHhrd"},"source":["# Run Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":593},"id":"osOmnLm-xiv_","executionInfo":{"status":"error","timestamp":1657981909953,"user_tz":-120,"elapsed":1418781,"user":{"displayName":"Piotr KulpiÅ„ski","userId":"05873078239734830768"}},"outputId":"e13c521e-0834-41d6-a663-f905f5fc024f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 01 | Epoch Time: 7m 5s\n","\tTrain Loss: 0.693 | Train Acc: 50.10%\n","\t Val. Loss: 0.693 |  Val. Acc: 50.07%\n","Epoch: 02 | Epoch Time: 7m 4s\n","\tTrain Loss: 0.693 | Train Acc: 50.08%\n","\t Val. Loss: 0.693 |  Val. Acc: 50.07%\n","Epoch: 03 | Epoch Time: 7m 5s\n","\tTrain Loss: 0.693 | Train Acc: 50.08%\n","\t Val. Loss: 0.693 |  Val. Acc: 50.07%\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-c4225fa196f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-29-d7e6b422f12f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# One epoch run around 7m on the full dataset\n","INPUT = len(embedding_dict)\n","EMBEDDING_DIM = dimension_of_embedding\n","HIDDEN_DIM = 256\n","OUTPUT_DIM = 1\n","PAD_ID = word_to_ix.get('<PAD>')\n","\n","model = RNN(INPUT, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, PAD_ID).to('cuda')\n","\n","model.embedding.from_pretrained(pretrained_embeddings, freeze=False, padding_idx=PAD_ID)\n","\n","N_EPOCHS = 10\n","\n","best_valid_loss = float('inf')\n","\n","import torch.optim as optim\n","\n","optimizer = optim.SGD(model.parameters(), lr=1e-3)\n","criterion = nn.BCEWithLogitsLoss()\n","def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division #\n","    acc = correct.sum() / len(correct)\n","    return acc\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, my_dataloader, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, val_dataloader, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut1-model.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["8fTe8WJD7CNi","CsAT4LLO7tud","gK44dOWs-o-T"],"machine_shape":"hm","name":"rnn.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}