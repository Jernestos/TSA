{"cells":[{"cell_type":"markdown","source":["This is the same as the lstm.ipynb, but the LSTM layer has been replaced by GRU."],"metadata":{"id":"d9R0PEeq76cp"}},{"cell_type":"markdown","metadata":{"id":"8fTe8WJD7CNi"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GuA7OFVyGcuL","executionInfo":{"status":"ok","timestamp":1659193000893,"user_tz":-120,"elapsed":32971,"user":{"displayName":"Gabriel Hug","userId":"09098341047120674226"}},"outputId":"ab0aea44-abc5-44d3-c833-1f9e66b3318a"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/CIL 2022\n","'code submission README.txt'\n"," data\n","'Final Results.gsheet'\n"," Models\n"," OLD\n"," Preprocessing\n","'README document.gdoc'\n","'Saved Model States'\n","'stanford glove+GRU_stanford glove_no-stemming_no-lemmatize_with-stopwords_no-spellcorrectno-stemming_no-lemmatize_with-stopwords_no-spellcorrect.txt'\n","'trained GRU_stanford glove_no-stemming_no-lemmatize_with-stopwords_no-spellcorrect.pkl'\n","'Word embeddings'\n"]}],"source":["#In this cell, there are various option for the user to freely choose:\n","#embedding_choice\n","#PREPROCESSING_CHOICE\n","\n","import time\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","import pandas as pd\n","import numpy as np\n","import torch\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from nltk.tokenize import TweetTokenizer\n","tknzr = TweetTokenizer()\n","\n","from gensim.models import Word2Vec\n","from gensim.models import FastText\n","from gensim.models import KeyedVectors\n","#from gensim.test.utils import common_texts\n","import gensim.downloader as api\n","import gensim\n","\n","#helper function to save models and stats\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n","import pickle\n","\n","\n","use_drive = True\n","if use_drive:\n","  PATH = \"/content/drive/MyDrive/CIL 2022/\"\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  %cd /content/drive/MyDrive/CIL 2022/\n","  !ls\n","else:\n","  PATH = \"./\"\n","\n","#save model\n","# now you can save it to a file\n","# with open('filename.pkl', 'wb') as f:\n","#     pickle.dump(clf, f)\n","\n","# # and later you can load it\n","# with open('filename.pkl', 'rb') as f:\n","#     clf = pickle.load(f)\n","\n","#1 = stanford glove\n","#2 = word2vec\n","#3 = fasttext\n","#4 = basic urban dictionary embedding\n","#5 = phrase urban dictionary embedding\n","def get_embedding_name(embedding_id):\n","  if embedding_id == 1:\n","    return \"stanford glove\"\n","  elif embedding_id == 2:\n","    return \"word2vec\"\n","  elif embedding_id == 3:\n","    return \"fasttext\"\n","  elif embedding_id == 4:\n","    return \"basic urban dictionary\"\n","  elif embedding_id == 5:\n","    return \"phrase urban dictionary\"\n","  else:\n","    return \"User error: embedding id does not exist.\"\n","\n","#Saving trained model\n","def save_model(model, model_name):\n","  name_of_file_model = \"trained \" + model_name + \".pkl\"\n","  with open(name_of_file_model, 'wb') as f:\n","    pickle.dump(model, f)\n","  print(\"Model saved.\")\n","\n","#Saving stats of model to a file\n","def save_stats_to_file(y_val, y_val_pred, model_name):\n","  name_of_file_stats = get_embedding_name(embedding_choice) + \"+\" + model_name + PREPROCESSING_CHOICE + \".txt\"\n","  # name_of_file_model = \"trained \" + model_name + \".pkl\"\n","  # print(\"Saving model to file.\")\n","  # with open(name_of_file_model, 'wb') as f:\n","  #   pickle.dump(model, f)\n","  print(\"Saving model relevant stats to file.\")\n","  file_obj = open(name_of_file_stats, \"w\", encoding=\"utf8\")\n","  file_obj.write(f'use_drive: {use_drive}\\n')\n","  # file_obj.write(f'LOAD_FROM_SPLITTED_DATASET: {LOAD_FROM_SPLITTED_DATASET}\\n')\n","  # file_obj.write(f'WRITE_SPLITTED_DATASET: {WRITE_SPLITTED_DATASET}\\n')\n","  # file_obj.write(f'REMOVE_DUPLICATES_FROM_TRAINING: {REMOVE_DUPLICATES_FROM_TRAINING}\\n')\n","  file_obj.write(f'PREPROCESSING_CHOICE: {PREPROCESSING_CHOICE}\\n')\n","  file_obj.write(f'embedding_choice: {embedding_choice}\\n')\n","  file_obj.write(f'embedding_name: {get_embedding_name(embedding_choice)}\\n')\n","  file_obj.write(f'dimension_of_embedding: {dimension_of_embedding}\\n')\n","  file_obj.write(f'Model name: {model_name}\\n')\n","  file_obj.write(f'Acc: {accuracy_score(y_val, y_val_pred)}\\n')\n","  file_obj.write(f'Recall: {recall_score(y_val, y_val_pred)}\\n')\n","  file_obj.write(f'Precision: {precision_score(y_val, y_val_pred)}\\n')\n","  file_obj.write(f'F1: {f1_score(y_val, y_val_pred)}\\n')\n","  file_obj.write(f'ROC_AUC: {roc_auc_score(y_val, y_val_pred)}\\n')\n","  file_obj.close()\n","  print(f'Acc: {accuracy_score(y_val, y_val_pred)}')\n","  print(f'Recall: {recall_score(y_val, y_val_pred)}')\n","  print(f'Precision: {precision_score(y_val, y_val_pred)}')\n","  print(f'F1: {f1_score(y_val, y_val_pred)}')\n","  print(f'ROC_AUC: {roc_auc_score(y_val, y_val_pred)}')\n","\n","\n","#Saving stats of model to a file\n","def save_epoch_to_file(epoch, valid_loss, valid_acc, model_name):\n","  name_of_file_stats = get_embedding_name(embedding_choice) + \"+\" + model_name + PREPROCESSING_CHOICE + \".txt\"\n","\n","  print(\"Saving model relevant stats to file.\")\n","  file_obj = open(name_of_file_stats, \"a\", encoding=\"utf8\")\n","  file_obj.write(f'Epoch number: {epoch}\\n')\n","  file_obj.write(f'PREPROCESSING_CHOICE: {PREPROCESSING_CHOICE}\\n')\n","  file_obj.write(f'embedding_choice: {embedding_choice}\\n')\n","  file_obj.write(f'embedding_name: {get_embedding_name(embedding_choice)}\\n')\n","  file_obj.write(f'dimension_of_embedding: {dimension_of_embedding}\\n')\n","  file_obj.write(f'Model name: {model_name}\\n')\n","  file_obj.write(f'Acc: {valid_acc*100:.2f}%\\n')\n","  file_obj.write(f'Loss: {valid_loss:.3f}\\n')\n","  file_obj.close()"]},{"cell_type":"markdown","metadata":{"id":"CsAT4LLO7tud"},"source":["# Choices"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XDU3yME88BbW"},"outputs":[],"source":["#Choose embedding below\n","#1 = stanford glove\n","#2 = word2vec\n","#3 = fasttext\n","#4 = basic urban dictionary embedding\n","#5 = phrase urban dictionary embedding\n","embedding_choice = 1\n","\n","USE_DICTIONARY = True\n","embedding_non_dict_model = None\n","embedding_dict = dict()\n","#SET FLAG \"USE_DICTIONARY\" to determine if we work with a dictionary or a loaded pretrained model\n","if (embedding_choice == 2) or (embedding_choice == 3):\n","  USE_DICTIONARY = False\n","\n","# HYPERPARAMETERS\n","# LOAD_FROM_SPLITTED_DATASET = True\n","# WRITE_SPLITTED_DATASET = True\n","# REMOVE_DUPLICATES_FROM_TRAINING = False\n","\n","#option 0 - 8\n","PREPROCESSING_OPTIONS = [ \"raw\",\n","\"no-stemming_no-lemmatize_no-stopwords_no-spellcorrect\",\n","\"no-stemming_no-lemmatize_with-stopwords_no-spellcorrect\",\n","\"no-stemming_no-lemmatize_with-stopwords_with-spellcorrect\",\n","\"no-stemming_with-lemmatize_with-stopwords_no-spellcorrect\",\n","\"no-stemming_with-lemmatize_with-stopwords_with-spellcorrect\",\n","\"with-stemming_no-lemmatize_with-stopwords_no-spellcorrect\",\n","\"with-stemming_with-lemmatize_no-stopwords_with-spellcorrect\",\n","\"with-stemming_with-lemmatize_with-stopwords_no-spellcorrect\" ]\n","PREPROCESSING_CHOICE = PREPROCESSING_OPTIONS[0] # one from PREPROCESSING_OPTIONS\n","\n","DEVICE = 'cuda'\n","N_EPOCHS = 30\n","\n","\n","model_name = \"GRU_\" + get_embedding_name(embedding_choice) + \"_\" + PREPROCESSING_CHOICE\n","\n","name_of_file_model = \"trained \" + model_name + \".pkl\"\n"]},{"cell_type":"markdown","metadata":{"id":"gK44dOWs-o-T"},"source":["#Choose embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G6BN0Yc_pJR4"},"outputs":[],"source":["#From the glove embedding file\n","\n","#https://github.com/RaRe-Technologies/gensim-data#datasets\n","#https://kavita-ganesan.com/easily-access-pre-trained-word-embeddings-with-gensim/#.YsGEXexBxE4\n","\n","#depending on choice, we choose a different file\n","if embedding_choice == 1:\n","  #stanford\n","  #files offers dimension_of_embedding = {25,50,100,200}\n","  dimension_of_embedding = 200 #can also modify this\n","\n","  #easy:\n","  # model_name = \"glove-twitter-\" + str(dimension_of_embedding)\n","  # model = api.load(model_name)\n","\n","  #directly from stanford glove file:\n","  path_to_embedding_file = \"/content/drive/MyDrive/CIL 2022/Word embeddings\"\n","  path_to_embedding_file += \"/Glove/glove.twitter.27B.\" + str(dimension_of_embedding) + \"d.txt\"\n","\n","  # FLAG_shaped_already_saved = False\n","  # shape_of_np_vector = None\n","\n","  embedding_file_obj = open(path_to_embedding_file, \"r\", encoding = \"utf8\")\n","  for line in embedding_file_obj:\n","    #Check if line consists only of ASCII characters (no Chinese/Japanse/Arabic, etc. expressions)\n","    #There were some lines that had non-ASCII characters.\n","    if line.isascii():\n","      word_n_vector = line.split()\n","      embedding_dict[word_n_vector[0]] = np.array(word_n_vector[1:], dtype=np.float64)\n","      # if not FLAG_shaped_already_saved:\n","      #   shape_of_np_vector = np.array(word_n_vector[1:], dtype=np.float64).shape\n","      #   FLAG_shaped_already_saved = True\n","\n","  embedding_file_obj.close\n","\n","  #add <UNKNOWN> token to vocabulary\n","  #choose the 0 vector as the corresponding embedding\n","  embedding_dict[\"<UNKNOWN>\"] = np.zeros(dimension_of_embedding, dtype=np.float64)\n","  embedding_dict[\"<PAD>\"] = np.zeros(dimension_of_embedding, dtype=np.float64)\n","  #embedding_dict[\"<UNKNOWN>\"] = np.zeros(shape_of_np_vector, dtype=np.float64)\n","\n","\n","elif embedding_choice == 2:\n","  \n","#https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html\n","\n","  #easier:\n","  dimension_of_embedding = 300\n","  #choose which embeddings\n","  # model_name = \"word2vec-google-news-300\"\n","  # model_name = \"word2vec-ruscorpora-300\" #get Russian vocabulary\n","  \n","  #IF PRE-TRAINED MODEL NOT STORED, LOAD IT FROM WEB\n","  model_name = \"word2vec-google-news-\" + str(dimension_of_embedding)\n","  embedding_non_dict_model = api.load(model_name) #load pretrained model\n","  #embedding_non_dict_model.save_word2vec_format('w2v_pre_trained_model.txt', binary=False) #store it #indicate path\n","\n","  #ELSE LOAD IT FROM FILE\n","  # pre_trained_model = \"/content/drive/MyDrive/CIL 2022/Models/w2v_pre_trained_model.txt\"\n","  # model = KeyedVectors.load_word2vec_format(pre_trained_model, binary=False)\n","\n","elif embedding_choice == 3:\n","\n","#https://radimrehurek.com/gensim/auto_examples/tutorials/run_fasttext.html#sphx-glr-auto-examples-tutorials-run-fasttext-py\n","  \n","  dimension_of_embedding = 300\n","  #choose which embeddings\n","  # model_name = \"word2vec-google-news-300\"\n","  # model_name = \"word2vec-ruscorpora-300\" #get Russian vocabulary\n","\n","  #IF PRE-TRAINED MODEL NOT STORED, LOAD IT FROM WEB\n","  model_name = \"fasttext-wiki-news-subwords-\" + str(dimension_of_embedding)\n","  embedding_non_dict_model = api.load(model_name) #load pretrained model\n","  \n","\n","  #ELSE LOAD IT FROM FILE\n","  # pre_trained_model = \"/content/drive/MyDrive/CIL 2022/Models/fasttext_pre_trained_model.txt\"\n","  # model = KeyedVectors.load_fasttext_format(pre_trained_model, binary=False)\n","  \n","\n","elif (embedding_choice == 4) or (embedding_choice == 5):\n","  \n","  #see https://aclanthology.org/2020.lrec-1.586.pdf for difference.\n","\n","  #TODO: figure out what the binaries do\n","  path_to_embedding_file = None\n","  if embedding_choice == 4:\n","    path_to_embedding_file = \"/content/drive/MyDrive/CIL 2022/Word embeddings/urbanDictionary/ud_basic.vec\"\n","  else:\n","    path_to_embedding_file = \"/content/drive/MyDrive/CIL 2022/Word embeddings/urbanDictionary/ud_phrase.vec\"\n","  \n","\n","  embedding_file_obj = open(path_to_embedding_file, \"r\")\n","  vocab_size_and_embedding_dim = embedding_file_obj.readline().split()\n","\n","  vocab_size = int(vocab_size_and_embedding_dim[0])\n","  dimension_of_embedding = int(vocab_size_and_embedding_dim[1])\n","\n","  # FLAG_shaped_already_saved = False\n","  # shape_of_np_vector = None\n","\n","  for line in embedding_file_obj:\n","    word_n_vector = line.split()\n","    embedding_dict[word_n_vector[0]] = np.array(word_n_vector[1:], dtype=np.float64)\n","    # if not FLAG_shaped_already_saved:\n","    #   shape_of_np_vector = np.array(word_n_vector[1:], dtype=np.float64).shape\n","    #   FLAG_shaped_already_saved = True\n","\n","  embedding_file_obj.close\n","\n","  #add <UNKNOWN> token to vocabulary\n","  #choose the 0 vector as the corresponding embedding\n","  embedding_dict[\"<UNKNOWN>\"] = np.zeros(dimension_of_embedding, dtype=np.float64)\n","  embedding_dict[\"<PAD>\"] = np.zeros(dimension_of_embedding, dtype=np.float64)\n","  #embedding_dict[\"<UNKNOWN>\"] = np.zeros(shape_of_np_vector, dtype=np.float64)\n","else:\n","  print(\"Error: embedding not recognized\")\n","\n","#init method"]},{"cell_type":"markdown","metadata":{"id":"VsdyEoMRqR7W"},"source":["# Tokenize to embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AIZrOTIOqRhG"},"outputs":[],"source":["\n","#https://www.nltk.org/api/nltk.tokenize.html\n","\n","#feature = average of vectors of tokens occuring in tweet\n","def transform_to_embeddings(list_of_sentences, embedding_model, embedding_model_type, word_to_ix):\n","\n","  max_size = 256\n","  sentences = torch.zeros(len(list_of_sentences), max_size, dtype=torch.long, device=DEVICE)#to return\n","  lengths = torch.zeros(len(list_of_sentences), dtype=torch.long, device='cpu')\n","    #for each tweet:\n","    #for each token:\n","    #get embedding vector\n","    #compute average\n","    #store it in a list with corresponding label\n","  pad_index = word_to_ix.get('<PAD>')\n","\n","  for line, tweet in enumerate(list_of_sentences):\n","    tokenized_tweet = tknzr.tokenize(tweet)\n","    indexed_embeddings = torch.tensor([pad_index]*max_size, dtype=torch.long, device=DEVICE)\n","    sentence_length = 0\n","    for index, word in enumerate(tokenized_tweet):\n","  \n","      word_index = word_to_ix.get(word)\n","      if word_index == None:\n","        word_index = word_to_ix.get(\"<UNKNOWN>\")\n","\n","      indexed_embeddings[index] = word_index\n","      sentence_length = sentence_length + 1\n","    sentences[line] = indexed_embeddings\n","    lengths[line] = sentence_length\n","  return sentences, lengths\n"]},{"cell_type":"markdown","metadata":{"id":"VXMlp9APzTew"},"source":["#Create training and test set"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8984,"status":"ok","timestamp":1659193038750,"user":{"displayName":"Gabriel Hug","userId":"09098341047120674226"},"user_tz":-120},"id":"vrxzzY3yGlZG","outputId":"bac45db7-5ae7-4d95-c25f-0ca125cdffcb"},"outputs":[{"output_type":"stream","name":"stdout","text":["1970002\n"]}],"source":["def read_file_and_strip(filename):\n","  lines = []\n","  with open(filename) as file:\n","    for line in file:\n","      lines.append(line.strip())\n","  return np.array(lines)\n","\n","def read_data():\n","  dataset_path = PATH + \"data/\" + PREPROCESSING_CHOICE + \"/\"\n","\n","  train_sentences = read_file_and_strip(dataset_path + \"train_sentences.txt\")\n","  train_labels = read_file_and_strip(dataset_path + \"train_labels.txt\").astype(int)\n","  val_sentences = read_file_and_strip(dataset_path + \"val_sentences.txt\")\n","  val_labels = read_file_and_strip(dataset_path + \"val_labels.txt\").astype(int)\n","  \n","  return train_sentences, train_labels, val_sentences, val_labels\n","\n","train_sentences, train_labels, val_sentences, val_labels = read_data()\n","print(len(train_sentences))\n","\n","\n","embedding_model = None\n","if USE_DICTIONARY:\n","  embedding_model_type = \"DICT\"\n","  embedding_model = embedding_dict\n","else:\n","  embedding_model_type = \"NON-DICT\"\n","  embedding_model = embedding_non_dict_model\n"]},{"cell_type":"markdown","metadata":{"id":"4v1Bawbd9bu4"},"source":["## Transform the sentences into tensor vectors of word indexes from the vocab corpus"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zDbne3KmGtgh"},"outputs":[],"source":["# Create a vocabulary corpus\n","word_to_ix = {word: i for i, word in enumerate(embedding_model)}\n","\n","train_data, train_lengths = transform_to_embeddings(train_sentences, embedding_model, embedding_model_type, word_to_ix)\n","\n","val_data, val_lengths = transform_to_embeddings(val_sentences, embedding_model, embedding_model_type, word_to_ix)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O1hySBw1BD9M"},"outputs":[],"source":["\n","train_labels = torch.tensor(train_labels, dtype=torch.long, device=DEVICE) \n","\n","val_labels = torch.tensor(val_labels, dtype=torch.long, device=DEVICE) "]},{"cell_type":"markdown","metadata":{"id":"eHmbBpVGe_Xx"},"source":["## Transform the embeddings into float tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LdvaS17ve7X7"},"outputs":[],"source":["# Transform the embeddings into float tensor with just weights and indexes of \n","# those weights representing the words\n","test = np.zeros((len(embedding_model), dimension_of_embedding))\n","for i, word in enumerate(embedding_model):\n","  test[i] = embedding_model[word]\n","\n","pretrained_embeddings = torch.tensor(test, dtype=torch.float, device=DEVICE)"]},{"cell_type":"markdown","metadata":{"id":"5isaz7VhZyM8"},"source":["#Model = RNN"]},{"cell_type":"markdown","metadata":{"id":"iLFoOdq392d0"},"source":["## Put tensor into a dataset for batching"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2gLKemU_IoJu"},"outputs":[],"source":["class Dataset(torch.utils.data.Dataset):\n","  'Characterizes a dataset for PyTorch'\n","  def __init__(self, list_id, labels, length):\n","        'Initialization'\n","        self.labels = labels\n","        self.list_id = list_id\n","        self.length = length\n","\n","  def __len__(self):\n","        'Denotes the total number of samples'\n","        return len(self.list_id)\n","\n","  def __getitem__(self, index):\n","        'Generates one sample of data'\n","\n","        # Load data and get label\n","        X = self.list_id[index]\n","        y = torch.tensor([self.labels[index]], dtype=torch.long, device=DEVICE)\n","        len = self.length[index]\n","        return X, y, len"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qObEZIzLx1o6"},"outputs":[],"source":["BATCH_SIZE = 512\n","\n","dataset = Dataset(train_data, train_labels, train_lengths)\n","my_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True) # create your dataloader\n","\n","val_dataset = Dataset(val_data, val_labels, val_lengths)\n","val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"atmM6qMuHYyX"},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l4hl3zzfoZiz"},"outputs":[],"source":["class RNN(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n","                 bidirectional, dropout, pad_idx):\n","        \n","        super().__init__()\n","        \n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n","        \n","        self.rnn = nn.GRU(embedding_dim, \n","                           hidden_dim, \n","                           num_layers=n_layers, \n","                           bidirectional=bidirectional, \n","                           dropout=dropout)\n","        \n","        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, text, text_lengths):\n","        \n","        #text = [sent len, batch size]\n","        \n","        embedded = self.dropout(self.embedding(text))\n","        \n","        #embedded = [sent len, batch size, emb dim]\n","        \n","        #pack sequence\n","        # lengths need to be on CPU!\n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'), enforce_sorted=False)\n","        \n","        packed_output, hidden = self.rnn(packed_embedded)\n","        \n","        #unpack sequence\n","        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n","\n","        #output = [sent len, batch size, hid dim * num directions]\n","        #output over padding tokens are zero tensors\n","        \n","        #hidden = [num layers * num directions, batch size, hid dim]\n","        #cell = [num layers * num directions, batch size, hid dim]\n","        \n","        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n","        #and apply dropout\n","        \n","        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n","                \n","        #hidden = [batch size, hid dim * num directions]\n","            \n","        return self.fc(hidden)"]},{"cell_type":"markdown","metadata":{"id":"VTdMqibYHbVC"},"source":["## Training method"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J9W6WD0pxdBg"},"outputs":[],"source":["def train(model, iterator, optimizer, lr_scheduler, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.train()\n","    \n","    for index, batch in enumerate(iterator):\n","        optimizer.zero_grad()\n","\n","        text, labels, lengths = batch\n","        labels = labels.type(torch.FloatTensor).to(DEVICE)\n","\n","        predictions = model(text.T, lengths)\n","        \n","        loss = criterion(predictions, labels)\n","        \n","        acc = binary_accuracy(predictions, labels)\n","        \n","        loss.backward()\n","        \n","        \n","        optimizer.step()\n","        lr_scheduler.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","          \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"]},{"cell_type":"markdown","metadata":{"id":"8nvUGXRsHedy"},"source":["## Evaluation method"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l7P0q5dHxewi"},"outputs":[],"source":["def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for index, batch in enumerate(iterator):\n","          text, labels, lengths = batch\n","\n","          labels = labels.type(torch.FloatTensor).to(DEVICE)\n","\n","          predictions = model(text.T, lengths)\n","          \n","          loss = criterion(predictions, labels)\n","          \n","          acc = binary_accuracy(predictions, labels)\n","          \n","\n","          epoch_loss += loss.item()\n","          epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FATKGGokxgw0"},"outputs":[],"source":["\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"]},{"cell_type":"markdown","metadata":{"id":"raGFUcxHHhrd"},"source":["# Run Model"]},{"cell_type":"code","source":["try:\n","  from transformers import AutoTokenizer\n","  print(\"transformers package already installed\")\n","except ModuleNotFoundError:\n","  ! pip install transformers datasets\n","  from transformers import AutoTokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"zILYu92c9vo_","executionInfo":{"status":"ok","timestamp":1659193701809,"user_tz":-120,"elapsed":12565,"user":{"displayName":"Gabriel Hug","userId":"09098341047120674226"}},"outputId":"854df3d5-9d24-4bd0-b42c-def27096d67a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 4.1 MB/s \n","\u001b[?25hCollecting datasets\n","  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n","\u001b[K     |████████████████████████████████| 365 kB 81.4 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 90.6 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 72.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 13.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 87.0 MB/s \n","\u001b[?25hCollecting fsspec[http]>=2021.11.1\n","  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n","\u001b[K     |████████████████████████████████| 141 kB 94.1 MB/s \n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 90.9 MB/s \n","\u001b[?25hRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, pyyaml, fsspec, xxhash, tokenizers, responses, huggingface-hub, transformers, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed datasets-2.4.0 fsspec-2022.7.1 huggingface-hub-0.8.1 pyyaml-6.0 responses-0.18.0 tokenizers-0.12.1 transformers-4.21.0 urllib3-1.25.11 xxhash-3.0.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["urllib3"]}}},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osOmnLm-xiv_","outputId":"9db71f31-0d3d-46d2-923c-44396fe7936c","executionInfo":{"status":"ok","timestamp":1659209026886,"user_tz":-120,"elapsed":15325102,"user":{"displayName":"Gabriel Hug","userId":"09098341047120674226"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 01 | Epoch Time: 8m 33s\n","\tTrain Loss: 0.542 | Train Acc: 70.88%\n","\t Val. Loss: 0.444 |  Val. Acc: 79.10%\n","Saving model relevant stats to file.\n","Epoch: 02 | Epoch Time: 8m 31s\n","\tTrain Loss: 0.446 | Train Acc: 78.42%\n","\t Val. Loss: 0.408 |  Val. Acc: 81.29%\n","Saving model relevant stats to file.\n","Epoch: 03 | Epoch Time: 8m 32s\n","\tTrain Loss: 0.412 | Train Acc: 80.64%\n","\t Val. Loss: 0.377 |  Val. Acc: 82.75%\n","Saving model relevant stats to file.\n","Epoch: 04 | Epoch Time: 8m 31s\n","\tTrain Loss: 0.389 | Train Acc: 82.06%\n","\t Val. Loss: 0.367 |  Val. Acc: 83.63%\n","Saving model relevant stats to file.\n","Epoch: 05 | Epoch Time: 8m 31s\n","\tTrain Loss: 0.373 | Train Acc: 82.98%\n","\t Val. Loss: 0.356 |  Val. Acc: 83.92%\n","Saving model relevant stats to file.\n","Epoch: 06 | Epoch Time: 8m 33s\n","\tTrain Loss: 0.362 | Train Acc: 83.59%\n","\t Val. Loss: 0.351 |  Val. Acc: 84.33%\n","Saving model relevant stats to file.\n","Epoch: 07 | Epoch Time: 8m 33s\n","\tTrain Loss: 0.355 | Train Acc: 83.99%\n","\t Val. Loss: 0.352 |  Val. Acc: 84.43%\n","Saving model relevant stats to file.\n","Epoch: 08 | Epoch Time: 8m 32s\n","\tTrain Loss: 0.351 | Train Acc: 84.30%\n","\t Val. Loss: 0.351 |  Val. Acc: 84.39%\n","Saving model relevant stats to file.\n","Epoch: 09 | Epoch Time: 8m 30s\n","\tTrain Loss: 0.348 | Train Acc: 84.45%\n","\t Val. Loss: 0.350 |  Val. Acc: 84.42%\n","Saving model relevant stats to file.\n","Epoch: 10 | Epoch Time: 8m 31s\n","\tTrain Loss: 0.348 | Train Acc: 84.45%\n","\t Val. Loss: 0.353 |  Val. Acc: 84.23%\n","Saving model relevant stats to file.\n","Epoch: 11 | Epoch Time: 8m 32s\n","\tTrain Loss: 0.350 | Train Acc: 84.38%\n","\t Val. Loss: 0.360 |  Val. Acc: 83.98%\n","Saving model relevant stats to file.\n","Epoch: 12 | Epoch Time: 8m 31s\n","\tTrain Loss: 0.355 | Train Acc: 84.10%\n","\t Val. Loss: 0.371 |  Val. Acc: 83.32%\n","Saving model relevant stats to file.\n","Epoch: 13 | Epoch Time: 8m 31s\n","\tTrain Loss: 0.369 | Train Acc: 83.32%\n","\t Val. Loss: 0.383 |  Val. Acc: 82.74%\n","Saving model relevant stats to file.\n","Epoch: 14 | Epoch Time: 8m 30s\n","\tTrain Loss: 0.393 | Train Acc: 81.92%\n","\t Val. Loss: 0.396 |  Val. Acc: 81.70%\n","Saving model relevant stats to file.\n","Epoch: 15 | Epoch Time: 8m 29s\n","\tTrain Loss: 0.404 | Train Acc: 81.23%\n","\t Val. Loss: 0.400 |  Val. Acc: 81.59%\n","Saving model relevant stats to file.\n","Epoch: 16 | Epoch Time: 8m 29s\n","\tTrain Loss: 0.411 | Train Acc: 80.83%\n","\t Val. Loss: 0.405 |  Val. Acc: 81.18%\n","Saving model relevant stats to file.\n","Epoch: 17 | Epoch Time: 8m 29s\n","\tTrain Loss: 0.417 | Train Acc: 80.45%\n","\t Val. Loss: 0.406 |  Val. Acc: 80.96%\n","Saving model relevant stats to file.\n","Epoch: 18 | Epoch Time: 8m 29s\n","\tTrain Loss: 0.419 | Train Acc: 80.35%\n","\t Val. Loss: 0.408 |  Val. Acc: 80.93%\n","Saving model relevant stats to file.\n","Epoch: 19 | Epoch Time: 8m 29s\n","\tTrain Loss: 0.412 | Train Acc: 80.74%\n","\t Val. Loss: 0.399 |  Val. Acc: 81.52%\n","Saving model relevant stats to file.\n","Epoch: 20 | Epoch Time: 8m 28s\n","\tTrain Loss: 0.406 | Train Acc: 81.12%\n","\t Val. Loss: 0.397 |  Val. Acc: 81.77%\n","Saving model relevant stats to file.\n","Epoch: 21 | Epoch Time: 8m 29s\n","\tTrain Loss: 0.398 | Train Acc: 81.57%\n","\t Val. Loss: 0.392 |  Val. Acc: 81.93%\n","Saving model relevant stats to file.\n","Epoch: 22 | Epoch Time: 8m 28s\n","\tTrain Loss: 0.393 | Train Acc: 81.85%\n","\t Val. Loss: 0.390 |  Val. Acc: 82.11%\n","Saving model relevant stats to file.\n","Epoch: 23 | Epoch Time: 8m 28s\n","\tTrain Loss: 0.386 | Train Acc: 82.24%\n","\t Val. Loss: 0.385 |  Val. Acc: 82.40%\n","Saving model relevant stats to file.\n","Epoch: 24 | Epoch Time: 8m 28s\n","\tTrain Loss: 0.380 | Train Acc: 82.62%\n","\t Val. Loss: 0.381 |  Val. Acc: 82.57%\n","Saving model relevant stats to file.\n","Epoch: 25 | Epoch Time: 8m 29s\n","\tTrain Loss: 0.374 | Train Acc: 82.94%\n","\t Val. Loss: 0.379 |  Val. Acc: 82.71%\n","Saving model relevant stats to file.\n","Epoch: 26 | Epoch Time: 8m 28s\n","\tTrain Loss: 0.369 | Train Acc: 83.21%\n","\t Val. Loss: 0.377 |  Val. Acc: 82.90%\n","Saving model relevant stats to file.\n","Epoch: 27 | Epoch Time: 8m 28s\n","\tTrain Loss: 0.365 | Train Acc: 83.44%\n","\t Val. Loss: 0.375 |  Val. Acc: 83.01%\n","Saving model relevant stats to file.\n","Epoch: 28 | Epoch Time: 8m 28s\n","\tTrain Loss: 0.363 | Train Acc: 83.55%\n","\t Val. Loss: 0.374 |  Val. Acc: 83.07%\n","Saving model relevant stats to file.\n","Epoch: 29 | Epoch Time: 8m 28s\n","\tTrain Loss: 0.361 | Train Acc: 83.66%\n","\t Val. Loss: 0.374 |  Val. Acc: 83.09%\n","Saving model relevant stats to file.\n","Epoch: 30 | Epoch Time: 8m 28s\n","\tTrain Loss: 0.360 | Train Acc: 83.67%\n","\t Val. Loss: 0.374 |  Val. Acc: 83.08%\n","Saving model relevant stats to file.\n"]}],"source":["INPUT_DIM = len(embedding_dict)\n","embedding_dim = dimension_of_embedding\n","hidden_dim = 256\n","output_dim = 1\n","n_layers = 3\n","bidirectional = True\n","dropout_rate = 0.5\n","pad_index = word_to_ix.get('<PAD>')\n","\n","model = RNN(INPUT_DIM, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout_rate, \n","             pad_index)\n","\n","model.embedding.from_pretrained(pretrained_embeddings, freeze=False, padding_idx=pad_index)\n","\n","\n","\n","best_valid_loss = float('inf')\n","best_valid_acc = float('inf')\n","\n","\n","from torch.optim import SGD, AdamW\n","\n","lr = 3e-3\n","optimizer = AdamW(model.parameters(), lr=lr)\n","from transformers import get_scheduler\n","\n","num_training_steps = N_EPOCHS * len(my_dataloader)\n","lr_scheduler = get_scheduler(\n","    name=\"cosine\", optimizer=optimizer, num_warmup_steps=50000, num_training_steps=num_training_steps\n",")\n","# optimizer = optim.Adam(model.parameters())\n","criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(DEVICE)\n","criterion = criterion.to(DEVICE)\n","\n","def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division #\n","    acc = correct.sum() / len(correct)\n","    return acc\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, my_dataloader, optimizer, lr_scheduler, criterion)\n","    valid_loss, valid_acc = evaluate(model, val_dataloader, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_acc < best_valid_acc:\n","        best_valid_acc = valid_acc\n","        torch.save(model.state_dict(), name_of_file_model)\n","    \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n","    save_epoch_to_file(epoch, valid_loss, valid_acc, model_name)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"gru.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}